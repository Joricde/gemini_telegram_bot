# bot/message_processing/prompt_manager.py

from sqlalchemy.orm import Session
from typing import Optional, List

from bot import APP_CONFIG, PROMPTS_CONFIG
from bot.database import SessionLocal
from bot.database import models as db_models
from bot.database.crud import (
    create_prompt,
    get_prompts_by_user,
    get_system_default_prompts,
    get_prompt_by_name,
    get_prompt_by_id,
    get_chat_session_state,
    create_or_update_chat_session_state,
    get_or_create_user
)
from bot.utils import log

# --- Prompt Upload Logic ---
NAME, SYSTEM_INSTRUCTION = range(2) # Stages for ConversationHandler

async def start_upload_prompt(user_id: str) -> str:
    """Initiates the prompt upload process."""
    db = SessionLocal()
    try:
        get_or_create_user(db, user_id=user_id) # Ensure user exists
    finally:
        db.close()
    return "è¯·å‘é€ä½ æƒ³è¦å®šä¹‰çš„è§’è‰²çš„**ç³»ç»ŸæŒ‡ä»¤ (System Instruction)**ã€‚\nä¾‹å¦‚ï¼šä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚"

async def received_system_instruction(user_id: str, instruction: str, context_user_data: dict) -> str:
    """Stores the system instruction and asks for the prompt name."""
    context_user_data['system_instruction'] = instruction
    return "å¾ˆå¥½ï¼ç°åœ¨è¯·ä¸ºè¿™ä¸ªè§’è‰²è®¾å®šä¸€ä¸ª**å”¯ä¸€çš„åç§°**ã€‚\nä¾‹å¦‚ï¼šæˆ‘çš„åŠ©æ‰‹"

async def received_prompt_name_and_create(user_id: str, name: str, context_user_data: dict) -> str:
    """Stores the prompt name, creates the prompt, and ends the conversation."""
    system_instruction = context_user_data.get('system_instruction')
    if not system_instruction:
        log.warning(f"System instruction not found in user_data for user {user_id} during prompt creation.")
        return "æŠ±æ­‰ï¼Œå‘ç”Ÿé”™è¯¯ï¼Œæ‰¾ä¸åˆ°ç³»ç»ŸæŒ‡ä»¤ã€‚è¯·é‡æ–°å¼€å§‹ /upload_promptã€‚"

    db = SessionLocal()
    try:
        # Check if prompt name already exists (system or user-created for this user)
        existing_prompt_system = get_prompt_by_name(db, name=name)
        if existing_prompt_system and existing_prompt_system.is_system_default:
            return f"è§’è‰²åç§° '{name}' ä¸ç³»ç»Ÿé¢„è®¾è§’è‰²å†²çªï¼Œè¯·æ¢ä¸€ä¸ªåç§°ï¼Œæˆ–ä½¿ç”¨ /set_prompt æ¥è®¾ç½®é¢„è®¾è§’è‰²ã€‚"

        existing_prompt_user_list = get_prompts_by_user(db, user_id=user_id)
        if any(p.name == name for p in existing_prompt_user_list):
            return f"ä½ å·²ç»åˆ›å»ºè¿‡ä¸€ä¸ªåä¸º '{name}' çš„è§’è‰²äº†ã€‚è¯·æ¢ä¸€ä¸ªåç§°ï¼Œæˆ–ä½¿ç”¨ /my_prompts æŸ¥çœ‹ã€‚"


        default_gen_params = APP_CONFIG.get("gemini_settings", {}).get("default_generation_parameters", {})
        # Use default generation parameters from app_config.yml
        new_prompt = create_prompt(
            db=db,
            name=name,
            system_instruction=system_instruction,
            creator_user_id=user_id,
            temperature=default_gen_params.get("temperature"),
            top_p=default_gen_params.get("top_p"),
            top_k=default_gen_params.get("top_k"),
            max_output_tokens=default_gen_params.get("max_output_tokens"),
            # base_model_override will use the global default from GeminiService if not set here
            is_system_default=False
        )
        if new_prompt:
            log.info(f"User {user_id} created new prompt '{name}' (ID: {new_prompt.id}).")
            context_user_data.clear() # Clear data after successful creation
            return (f"è§’è‰² '{name}' åˆ›å»ºæˆåŠŸï¼\n"
                    f"ä½ å¯ä»¥ä½¿ç”¨ /my_prompts æŸ¥çœ‹ï¼Œæˆ–ä½¿ç”¨ /set_prompt {name} æ¥æ¿€æ´»å®ƒã€‚")
        else:
            log.error(f"Failed to create prompt '{name}' for user {user_id} in DB.")
            return "åˆ›å»ºè§’è‰²æ—¶å‘ç”Ÿæ•°æ®åº“é”™è¯¯ï¼Œè¯·ç¨åå†è¯•ã€‚"
    except Exception as e:
        log.error(f"Exception creating prompt '{name}' for user {user_id}: {e}", exc_info=True)
        return "åˆ›å»ºè§’è‰²æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯ã€‚"
    finally:
        db.close()

async def cancel_upload_prompt(user_id: str, context_user_data: dict) -> str:
    """Cancels the prompt upload process."""
    context_user_data.clear()
    log.info(f"User {user_id} cancelled prompt upload.")
    return "è§’è‰²åˆ›å»ºå·²å–æ¶ˆã€‚"

# --- List Prompts Logic ---
async def list_my_prompts(user_id: str) -> str:
    """Lists user-created and system default prompts."""
    db = SessionLocal()
    try:
        user_prompts = get_prompts_by_user(db, user_id=user_id)
        system_prompts = get_system_default_prompts(db)

        response_lines = ["ğŸ“š **å¯ç”¨çš„è§’è‰² (Prompts)**:\n"]

        active_session_state = get_chat_session_state(db, telegram_chat_id=user_id, telegram_user_id=user_id)
        active_prompt_id = active_session_state.active_prompt_id if active_session_state else None

        response_lines.append("--- ä½ åˆ›å»ºçš„è§’è‰² ---")
        if user_prompts:
            for p in user_prompts:
                is_active = " (å½“å‰æ¿€æ´»)" if p.id == active_prompt_id else ""
                response_lines.append(f"- `{p.name}`{is_active}")
        else:
            response_lines.append("_ä½ è¿˜æ²¡æœ‰åˆ›å»ºä»»ä½•è§’è‰²ã€‚ä½¿ç”¨ /upload_prompt åˆ›å»ºä¸€ä¸ªå§ï¼_")

        response_lines.append("\n--- ç³»ç»Ÿé¢„è®¾è§’è‰² ---")
        if system_prompts:
            for p in system_prompts:
                is_active = " (å½“å‰æ¿€æ´»)" if p.id == active_prompt_id else ""
                response_lines.append(f"- `{p.name}`{is_active}")
        else:
            response_lines.append("_æ²¡æœ‰å¯ç”¨çš„ç³»ç»Ÿé¢„è®¾è§’è‰²ã€‚_")

        response_lines.append(f"\nä½¿ç”¨ `/set_prompt <è§’è‰²åç§°>` æ¥åˆ‡æ¢è§’è‰²ã€‚")
        return "\n".join(response_lines)
    finally:
        db.close()

# --- Set Prompt Logic ---
async def set_active_prompt(user_id: str, prompt_identifier: str) -> str:
    """Sets the active prompt for the user's private chat."""
    db = SessionLocal()
    try:
        # Try to get prompt by ID first if identifier is a number
        prompt_to_set: Optional[db_models.Prompt] = None
        if prompt_identifier.isdigit():
            prompt_to_set = get_prompt_by_id(db, prompt_id=int(prompt_identifier))

        # If not found by ID or identifier is not a number, try by name
        if not prompt_to_set:
            prompt_to_set = get_prompt_by_name(db, name=prompt_identifier)

        if not prompt_to_set:
            return f"æ‰¾ä¸åˆ°åä¸ºæˆ–IDä¸º '{prompt_identifier}' çš„è§’è‰²ã€‚è¯·ä½¿ç”¨ /my_prompts æŸ¥çœ‹å¯ç”¨è§’è‰²ã€‚"

        # Check if the prompt is either system default or created by the user
        if not prompt_to_set.is_system_default and prompt_to_set.creator_user_id != user_id:
            return f"ä½ æ— æ³•è®¾ç½®è§’è‰² '{prompt_identifier}'ï¼Œå› ä¸ºå®ƒä¸å±äºä½ ï¼Œä¹Ÿä¸æ˜¯ç³»ç»Ÿé¢„è®¾è§’è‰²ã€‚"

        # Get current session state or create if it doesn't exist
        # (though it should exist if they are chatting)
        session_state = get_chat_session_state(db, telegram_chat_id=user_id, telegram_user_id=user_id)

        if session_state:
            if session_state.active_prompt_id == prompt_to_set.id:
                return f"è§’è‰² '{prompt_to_set.name}' å·²ç»æ˜¯ä½ å½“å‰çš„æ¿€æ´»è§’è‰²äº†ã€‚"

            # Determine the base model for the new session
            new_base_model = prompt_to_set.base_model_override or \
                             APP_CONFIG.get("gemini_settings", {}).get("default_base_model", "gemini-1.5-flash")

            create_or_update_chat_session_state(
                db=db,
                telegram_chat_id=user_id,
                telegram_user_id=user_id,
                active_prompt_id=prompt_to_set.id,
                current_base_model=new_base_model,
                gemini_chat_history=None  # Reset history when prompt changes
            )
            log.info(f"User {user_id} set active prompt to '{prompt_to_set.name}' (ID: {prompt_to_set.id}). Chat history reset.")
            return (f"å·²åˆ‡æ¢åˆ°è§’è‰²: **{prompt_to_set.name}**ã€‚\n"
                    "ä¸TAçš„æ–°å¯¹è¯å·²ç»å¼€å§‹ï¼")
        else:
            # This case should ideally not happen if user has interacted before /start
            # If it does, create a new session state with this prompt
            default_base_model = prompt_to_set.base_model_override or \
                                 APP_CONFIG.get("gemini_settings", {}).get("default_base_model", "gemini-1.5-flash")
            get_or_create_user(db, user_id=user_id) # Ensure user exists
            create_or_update_chat_session_state(
                db=db,
                telegram_chat_id=user_id,
                telegram_user_id=user_id,
                active_prompt_id=prompt_to_set.id,
                current_base_model=default_base_model,
                gemini_chat_history=None
            )
            log.info(f"User {user_id} set initial active prompt to '{prompt_to_set.name}' (ID: {prompt_to_set.id}). New session created.")
            return (f"å·²ä¸ºä½ è®¾ç½®åˆå§‹è§’è‰²: **{prompt_to_set.name}**ã€‚\n"
                    "ç°åœ¨å¯ä»¥å¼€å§‹å¯¹è¯äº†ï¼")

    except Exception as e:
        log.error(f"Error setting active prompt '{prompt_identifier}' for user {user_id}: {e}", exc_info=True)
        return "è®¾ç½®è§’è‰²æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯ã€‚"
    finally:
        db.close()